# news path
data_dir: ../data/THUCNews/news
pretrained_path: /data/Learn_Project/Backup_Data/tiny_bert_chinese_pretrained
save_path: ../data/THUCNews/news/model.ckpt

# model parameter
gpu: '0'
epoches: 16
lr: 0.005
batch_size: 256
sent_max_len: 256


# text cnn parameters
pretrained_weight: False
pretrained_weight_path: ./pretrained_weight_emb.npy

kernel_size: [3, 4, 5]
num_kernels: 100
vocab_size: 21128  # same with albert vocab_size
embedding_dim: 64
num_class: 10

stride: 1
padding_index: 0
dropout: 0.3

