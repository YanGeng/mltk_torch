**TextCNN**

TextCNN,将CNN应用在NLP上，模型简单，主要做了如下试验

1. 在不加载预训练文件，随机初始化embedding,单独使用textCNN,2个epoch准确率0.8773，高于albert（0.79），可见text-cnn奇效。
不过这可能与bert网络深参数多，未作调参有关。
2. 也可以先通过bert或word2vec得到训练文本中所有的涉及的字的embedding，作为预训练embedding，下游接textCNN（
此部分调通了代码，未得完整结果，感兴趣可自行试验）


以上试验均未作仔细调参，怎么跑起这个代码。

1. 下载数据集 THUCNews（http://thuctc.thunlp.org/） 在这里，只切出了一部分数据做试验（没用完整数据集，完整数据集太大）。  
2. 打开config文件，将上述文件放到相应位置
接下来就可以跑了。
>python train.py  


数据：10个类  
{'体育': 0, '娱乐': 1, '家居': 2, '房产': 3, '教育': 4, '时尚': 5, '时政': 6, '游戏': 7, '科技': 8, '财经': 9}  


TextCNN Result:  
Epoch: 004; loss = 0.3286 cost time  28.8052
Accuracy: 0.8773 Loss in test 0.5226

classification result report: 
Epoch: 002; loss = 0.2188 cost time  45.0300

              precision    recall  f1-score   support

          体育     0.9035    0.8430    0.8722      1000
          娱乐     0.8611    0.9300    0.8942      1000
          家居     0.8076    0.8060    0.8068      1000
          房产     0.9568    0.9310    0.9437      1000
          教育     0.8666    0.7730    0.8171      1000
          时尚     0.8487    0.9140    0.8801      1000
          时政     0.9124    0.8120    0.8593      1000
          游戏     0.9497    0.9070    0.9279      1000
          科技     0.8614    0.9260    0.8925      1000
          财经     0.8261    0.9310    0.8754      1000

        accuracy                         0.8773     10000   
       macro avg     0.8794    0.8773    0.8769     10000
    weighted avg     0.8794    0.8773    0.8769     10000
         [[843  18  81   2   4  24   8   1   8  11]
         [  9 930  13   2   3  16   4   2   8  13]
         [ 55  48 806   1  39   6  19   7  11   8]
         [  2   6   4 931   8  21   7   1   4  16]
         [  9  16  42   6 773  30  18   3  72  31]
         [  3  19   3  14   9 914  12   5   8  13]
         [  8  27  40   7  22  40 812  15  10  19]
         [  1   5   3   4   3   8   5 907  12  52]
         [  1   6   4   2  20   2   3   3 926  33]
         [  2   5   2   4  11  16   2  11  16 931]]

    accuracy                         0.9224      5000
       macro avg     0.9255    0.9224    0.9200      5000
    weighted avg     0.9255    0.9224    0.9200      5000
         [[497   0   0   0   2   0   0   1   0   0]
         [  2 485   0   0   6   0   0   6   0   1]
         [  3   3 365  48  22   2  17   7  12  21]
         [  2   0   5 456  12   0  17   3   0   5]
         [  8   0   3   2 346   1  34  94  10   2]
         [  0   0   0   0   0 500   0   0   0   0]
         [  0   0   2   5   5   0 487   1   0   0]
         [  0   0   0   0   2   0   2 495   0   1]
         [  0   0   4   0   2   1   1   5 486   1]
         [  0   0   0   2   0   0   3   0   0 495]]



