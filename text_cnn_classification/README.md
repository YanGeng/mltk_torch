**TextCNN**

TextCNN,将CNN应用在NLP上，模型简单，主要做了如下试验

1. 在不加载预训练文件，随机初始化embedding,单独使用textCNN,2个epoch准确率0.9224，高于bert（0.8400），可见text-cnn奇效。
不过这可能与bert网络深参数多，未作调参有关。
2. 也可以先通过bert或word2vec得到训练文本中所有的涉及的字的embedding，作为预训练embedding，下游接textCNN（
此部分调通了代码，未得完整结果，感兴趣可自行试验）


以上试验均未作仔细调参，怎么跑起这个代码。

1. 下载数据集 THUCNews（http://thuctc.thunlp.org/） 在这里，只切出了一部分数据做试验（没用完整数据集，完整数据集太大）。  
用作试验的部分数据在这里（https://pan.baidu.com/s/1J28HP5Sf32V4n19PRHaV5A  提取码：ddup）  
2. 打开config文件，将上述文件放到相应位置
接下来就可以跑了。
>python train.py  


显卡：一块1050Ti  
数据：10个类  
{'体育': 0, '娱乐': 1, '家居': 2, '房产': 3, '教育': 4, '时尚': 5, '时政': 6, '游戏': 7, '科技': 8, '财经': 9}  


TextCNN Result:  
Accuracy: 0.9224 Loss in test 0.2708

classification result report: 
Epoch: 002; loss = 0.2188 cost time  45.0300

              precision    recall  f1-score   support

          体育     0.9707    0.9940    0.9822       500
          娱乐     0.9939    0.9700    0.9818       500
          家居     0.9631    0.7300    0.8305       500
          房产     0.8889    0.9120    0.9003       500
          教育     0.8715    0.6920    0.7715       500
          时尚     0.9921    1.0000    0.9960       500
          时政     0.8681    0.9740    0.9180       500
          游戏     0.8088    0.9900    0.8903       500
          科技     0.9567    0.9720    0.9643       500
          财经     0.9411    0.9900    0.9649       500

    accuracy                         0.9224      5000
       macro avg     0.9255    0.9224    0.9200      5000
    weighted avg     0.9255    0.9224    0.9200      5000
         [[497   0   0   0   2   0   0   1   0   0]
         [  2 485   0   0   6   0   0   6   0   1]
         [  3   3 365  48  22   2  17   7  12  21]
         [  2   0   5 456  12   0  17   3   0   5]
         [  8   0   3   2 346   1  34  94  10   2]
         [  0   0   0   0   0 500   0   0   0   0]
         [  0   0   2   5   5   0 487   1   0   0]
         [  0   0   0   0   2   0   2 495   0   1]
         [  0   0   4   0   2   1   1   5 486   1]
         [  0   0   0   2   0   0   3   0   0 495]]



