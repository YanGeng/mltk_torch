**本项目基于hugging face的transformer库，pytorch bert应用。**

写了个bert做文本分类的，写了调tiny_albert_chinese，bert_base_chinese的两种，大同小异，很容易上手。  


可以很轻松跑起这个代码
1. 上hugging face下载对应bert的预训练文件
2. 数据集已上传，data目录下。
3. 打开config文件，将上述文件放到相应位置，修改config对应的路径、hidden_size参数
接下来就可以跑了。
>python train.py



## Albert Result:  
Epoch: 011; loss = 0.6732 cost time  15.6404
Accuracy: 0.7926 Loss in test 0.6357
              precision    recall  f1-score   support

          体育     0.7173    0.6900    0.7034      1000
          娱乐     0.8621    0.7750    0.8162      1000
          家居     0.6067    0.7390    0.6664      1000
          房产     0.8998    0.8890    0.8944      1000
          教育     0.7528    0.6700    0.7090      1000
          时尚     0.7669    0.8720    0.8161      1000
          时政     0.8424    0.6630    0.7420      1000
          游戏     0.9363    0.9120    0.9240      1000
          科技     0.7781    0.8800    0.8259      1000
          财经     0.8245    0.8360    0.8302      1000

    accuracy                         0.7926     10000
       macro avg     0.7987    0.7926    0.7928     10000
    weighted avg     0.7987    0.7926    0.7928     10000
     [[690  23 190   2  37  21   9   8  19   1]
     [ 47 775  62  11  16  22  13   6  23  25]
     [126  27 739   3  43   4  29   4  22   3]
     [  7   6  19 889  10  24  13   3  14  15]
     [ 32  16 100  10 670  40  22   8  85  17]
     [ 11  17   9  22  11 872  13   3  16  26]
     [ 38  15  64  35  31  76 663   7  32  39]
     [  3   4   7   2   2  13   9 912   3  45]
     [  3   5  18   4  51  20  11   1 880   7]
     [  5  11  10  10  19  45   5  22  37 836]]

## macbert Result: 
Epoch: 008; loss = 0.3178 cost time  137.4945
Accuracy: 0.9156 Loss in test 0.2811
              precision    recall  f1-score   support

          体育     0.9203    0.8770    0.8981      1000
          娱乐     0.9529    0.9100    0.9309      1000
          家居     0.8299    0.8880    0.8580      1000
          房产     0.9174    0.9770    0.9462      1000
          教育     0.8645    0.8740    0.8692      1000
          时尚     0.9002    0.9380    0.9187      1000
          时政     0.9345    0.8700    0.9011      1000
          游戏     0.9711    0.9730    0.9720      1000
          科技     0.9485    0.9210    0.9346      1000
          财经     0.9280    0.9280    0.9280      1000

        accuracy                         0.9156     10000
       macro avg     0.9167    0.9156    0.9157     10000
    weighted avg     0.9167    0.9156    0.9157     10000
     [[877  15  79   3   7   9   6   1   0   3]
     [ 12 910  24   5   6  14   6   5   4  14]
     [ 46  14 888   3  22   1  21   3   1   1]
     [  0   0   2 977   4   9   5   1   0   2]
     [  6   3  39   9 874  18   8   0  32  11]
     [  2   6   1  21   7 938   9   1   2  13]
     [  6   4  23  30  26  35 870   0   0   6]
     [  1   1   3   2   3   2   1 973   2  12]
     [  0   0   7   4  48   6   3   1 921  10]
     [  3   2   4  11  14  10   2  17   9 928]]