# data path
data_dir: ../data/THUCNews/news
save_path: ../ckpt/albert_classification

# BERT parameter setup (change here while changing pre-train model)
pretrained_path: /data/Learn_Project/Backup_Data/bert_chinese
bert_type: bert  #  bert(macbert) or tiny_bert
hidden_size: 768 #  bert(macbert): 768 or tiny_albert: 312
pooling_type: first-last-avg

# model parameter setup
gpu: '0'
epoch: 12
lr: 0.05
batch_size: 512
sent_max_len: 42